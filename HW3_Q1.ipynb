{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_Q1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IzXxPD74UaH8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgba\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "id": "RGoY8zkQUdH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41dcd6ce-b58a-4cfb-e1d6-2ca490a4d5e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting the seed"
      ],
      "metadata": {
        "id": "bqikC__QUfAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4660a4be-36c3-4fb6-9f19-5c8c666aa6b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8ea40d63b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "DaTCWyJTUkD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc713079-f218-4a57-fda5-67072110ce37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "vxojgFOHU5G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fac810-a561-414f-9410-7304aed7fef2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize() # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\") # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "0-28EDlSU7bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.backends.cudnn.determinstic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "YNujJDxPVEFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "\n",
        "data_path = '../data'\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "data_labels = ('plane', 'car', 'bird', 'cat', )\n"
      ],
      "metadata": {
        "id": "XLQAsR9tX-AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Initialize the modules we need to build the network\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8-5_pTZyO8Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleClassifier2(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Initialize the modules we need to build the network\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        self.conv3 = nn.Conv2d(12,24,5)\n",
        "        self.fc1 = nn.Linear(24*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84,42)\n",
        "        self.fc4 = nn.Linear(42, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 24*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PzMCQj1CO2vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier()\n",
        "# Printing a module shows all its submodules\n",
        "print(model)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        " print(f\"Parameter {name}, shape {param.shape}\")"
      ],
      "metadata": {
        "id": "DjuBq2KYVH11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8a33b9-fb0d-44aa-d21a-80a7320b1be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Parameter conv1.weight, shape torch.Size([6, 3, 5, 5])\n",
            "Parameter conv1.bias, shape torch.Size([6])\n",
            "Parameter conv2.weight, shape torch.Size([16, 6, 5, 5])\n",
            "Parameter conv2.bias, shape torch.Size([16])\n",
            "Parameter fc1.weight, shape torch.Size([120, 400])\n",
            "Parameter fc1.bias, shape torch.Size([120])\n",
            "Parameter fc2.weight, shape torch.Size([84, 120])\n",
            "Parameter fc2.bias, shape torch.Size([84])\n",
            "Parameter fc3.weight, shape torch.Size([10, 84])\n",
            "Parameter fc3.bias, shape torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SimpleClassifier()\n",
        "print(model)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        " print(f\"Parameter {name}, shape {param.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U58p_qjonWwx",
        "outputId": "565c643a-82ab-42c5-c059-c228f6d94216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Parameter conv1.weight, shape torch.Size([6, 3, 5, 5])\n",
            "Parameter conv1.bias, shape torch.Size([6])\n",
            "Parameter conv2.weight, shape torch.Size([16, 6, 5, 5])\n",
            "Parameter conv2.bias, shape torch.Size([16])\n",
            "Parameter fc1.weight, shape torch.Size([120, 400])\n",
            "Parameter fc1.bias, shape torch.Size([120])\n",
            "Parameter fc2.weight, shape torch.Size([84, 120])\n",
            "Parameter fc2.bias, shape torch.Size([84])\n",
            "Parameter fc3.weight, shape torch.Size([10, 84])\n",
            "Parameter fc3.bias, shape torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"data loader - Pre-processing\"\n",
        "data_loader = data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(data_loader))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N], where d_1,...,d_N are the dimensions of the data points\n",
        "#print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ],
      "metadata": {
        "id": "0-WzY5e-loRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9938f5d5-e958-4133-bb93-84252de69b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data labels torch.Size([2]) \n",
            " tensor([1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Saving the Trained model\"\n",
        "state_dict = model.state_dict()\n",
        "print(state_dict)\n",
        "# torch.save(object, filename). For the filename, any extension can be used\n",
        "torch.save(state_dict, \"our_model.tar\")\n",
        "# Load state dict from the disk (make sure it is the same name as above)\n",
        "state_dict = torch.load(\"our_model.tar\")\n",
        "# Create a new model and load the state\n",
        "new_model = SimpleClassifier()\n",
        "new_model.load_state_dict(state_dict)\n",
        "# Verify that the parameters are the same\n",
        "print(\"Original model\\n\", model.state_dict())\n",
        "print(\"\\nLoaded model\\n\", new_model.state_dict())"
      ],
      "metadata": {
        "id": "bjzZQMg-lxGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Evaluation Code\"\n",
        "test_dataset = test_dataset\n",
        "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
        "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False,\n",
        "drop_last=False)\n",
        "\n",
        "def eval_model(model, data_loader):\n",
        "    model.eval() # Set model to eval mode\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    \n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            \n",
        "            # Determine prediction of model on dev set\n",
        "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            preds = torch.max(preds) # Sigmoid to map predictions between 0 and 1\n",
        "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
        "            \n",
        "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            true_preds += (pred_labels == data_labels).sum()\n",
        "            num_preds += data_labels.shape[0]\n",
        "            \n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")\n",
        "    \n",
        "eval_model(model, test_data_loader)"
      ],
      "metadata": {
        "id": "O1PaCcnpmPsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fa730a-22cf-4163-e910-48387ca33c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 10.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorboard logger from PyTorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Load tensorboard extension for Jupyter Notebook, only need to start TB in the notebook\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "Llhw4Lfmn86D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Training Code\"\n",
        "loss_module = nn.CrossEntropyLoss()\n",
        "# Input to the optimizer are the parameters of the model: model.parameters()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "data_loader = data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "# Push model to device. Has to be only done once\n",
        "model.to(device)\n",
        "\n",
        "def train_model(model, optimizer, data_loader, loss_module, num_epochs=20):\n",
        " # Set model to train mode\n",
        "    model.train()\n",
        "     # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "            #Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels)\n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad() \n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "#train_model(model, optimizer, data_loader, loss_module)"
      ],
      "metadata": {
        "id": "mAs98lnElrvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_logger(model, optimizer, data_loader, loss_module, val_dataset, num_epochs=100, logging_dir='runs/our_experiment'):\n",
        "    # Create TensorBoard logger\n",
        "    writer = SummaryWriter(logging_dir)\n",
        "    model_plotted = False\n",
        "    \n",
        "    # Set model to train mode\n",
        "    model.train() \n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0.0\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            \n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "            \n",
        "            # For the very first batch, we visualize the computation graph in TensorBoard\n",
        "            if not model_plotted:\n",
        "                writer.add_graph(model, data_inputs)\n",
        "                model_plotted = True\n",
        "            \n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "            \n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels)\n",
        "            \n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad() \n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "            \n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            ## Step 6: Take the running average of the loss\n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "        # Add average loss to TensorBoard\n",
        "        epoch_loss /= len(data_loader)\n",
        "        writer.add_scalar('training_loss',\n",
        "                          epoch_loss,\n",
        "                          global_step = epoch + 1)\n",
        "        \n",
        "        # Visualize prediction and add figure to TensorBoard\n",
        "        # Since matplotlib figures can be slow in rendering, we only do it every 10th epoch\n",
        "        # if (epoch + 1) % 10 == 0:\n",
        "        #     fig = visualize_classification(model, val_dataset.data, val_dataset.label)\n",
        "        #     writer.add_figure('predictions',\n",
        "        #                       fig,\n",
        "        #                       global_step = epoch + 1)\n",
        "    \n",
        "    writer.close()"
      ],
      "metadata": {
        "id": "jwUGoYhSpSu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train_model_with_logger(model, optimizer, data_loader, loss_module, val_dataset=test_dataset)"
      ],
      "metadata": {
        "id": "Fx1XGN99pXme",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "163f24b9-1781-4af4-c25a-0e00683b4d29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-799bb286694a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_model_with_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SimpleClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import simplefilter\n",
        "eval_model(model, data_loader)"
      ],
      "metadata": {
        "id": "vj_5APK2aeHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d89d680c-9461-4ea5-8fd2-2cd781ba2597"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-705f1e771d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimplefilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "j1EustMY6QXi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "65f8b316-32b6-4c9b-83f1-e0bef4662ad2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SimpleClassifier2().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train_model_with_logger(model2, optimizer, data_loader, loss_module, val_dataset=test_dataset)"
      ],
      "metadata": {
        "id": "KvI-QR5uVezA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "981007bb-1a57-429f-d4c5-31ef3e793900"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a59b43ea1885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleClassifier2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_model_with_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SimpleClassifier2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model2, data_loader)"
      ],
      "metadata": {
        "id": "X_mjI8WskyaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}